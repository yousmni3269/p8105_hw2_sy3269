p8105_hw2_sy3269.Rmd
================

Required packages (e.g.`tidyverse` and `readxl`) are installed.

# Problem 1

``` r
metro_df = 
  read_csv("./NYC_Transit_Subway_Entrance_And_Exit_Data.csv",  na = c("NA", "", ".")) |>
  janitor::clean_names() |>
  select(line:route11, entry, vending, entrance_type, ada) |>
  mutate(
    entry = case_match(
      entry, 
      "YES" ~ TRUE,
      "NO" ~ FALSE
    ))
```

    ## Rows: 1868 Columns: 32
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## chr (22): Division, Line, Station Name, Route1, Route2, Route3, Route4, Rout...
    ## dbl  (8): Station Latitude, Station Longitude, Route8, Route9, Route10, Rout...
    ## lgl  (2): ADA, Free Crossover
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

``` r
metro_df
```

    ## # A tibble: 1,868 × 19
    ##    line     station_name station_latitude station_longitude route1 route2 route3
    ##    <chr>    <chr>                   <dbl>             <dbl> <chr>  <chr>  <chr> 
    ##  1 4 Avenue 25th St                  40.7             -74.0 R      <NA>   <NA>  
    ##  2 4 Avenue 25th St                  40.7             -74.0 R      <NA>   <NA>  
    ##  3 4 Avenue 36th St                  40.7             -74.0 N      R      <NA>  
    ##  4 4 Avenue 36th St                  40.7             -74.0 N      R      <NA>  
    ##  5 4 Avenue 36th St                  40.7             -74.0 N      R      <NA>  
    ##  6 4 Avenue 45th St                  40.6             -74.0 R      <NA>   <NA>  
    ##  7 4 Avenue 45th St                  40.6             -74.0 R      <NA>   <NA>  
    ##  8 4 Avenue 45th St                  40.6             -74.0 R      <NA>   <NA>  
    ##  9 4 Avenue 45th St                  40.6             -74.0 R      <NA>   <NA>  
    ## 10 4 Avenue 53rd St                  40.6             -74.0 R      <NA>   <NA>  
    ## # ℹ 1,858 more rows
    ## # ℹ 12 more variables: route4 <chr>, route5 <chr>, route6 <chr>, route7 <chr>,
    ## #   route8 <dbl>, route9 <dbl>, route10 <dbl>, route11 <dbl>, entry <lgl>,
    ## #   vending <chr>, entrance_type <chr>, ada <lgl>

The NYC subway data was imported and cleaned using a
`janitor::clean_names` function. Then the entry variable was converted
from a character variable to a logical one using `case_match`. Then only
the required variables were listed out to remove unnecessary information
from the data set.

The NYC metro data set contains line, station name, station location
(latitude and longitude), routes served, entry and vending availability,
entrance type, and ada compliance information.

The dimension of the data set is 1868 x 19. The data set is in human
readable form but not yet tidy.

``` r
unique_stn = distinct(metro_df, station_name, line, ada)

ada_stn = filter(unique_stn, ada == TRUE)

nv_stn = filter(metro_df, vending == "NO")

nv_entry_stn = filter(nv_stn, entry == TRUE)
```

There are 465 distinct stations and there are 84 ADA compliant stations.

69 stations out of 183 stations without vending allow entrance. The
proportion is about 2.6521739.

``` r
new_metro_df = 
  read_csv("./NYC_Transit_Subway_Entrance_And_Exit_Data.csv", na = c("NA", "", ".")) |>
  janitor::clean_names() |> 
  mutate(
    route7 = as.character(route7),
    route8 = as.character(route8),
    route9 = as.character(route9),
    route10 = as.character(route10),
    route11 = as.character(route11)
  ) |> 
  select(line, station_name, route1:route11, entry, vending, entrance_type, ada) |>
  pivot_longer( 
    cols = route1:route11,
    names_to = "route_number",
    values_to = "route_name",
    names_prefix = "route"
  )
```

    ## Rows: 1868 Columns: 32
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## chr (22): Division, Line, Station Name, Route1, Route2, Route3, Route4, Rout...
    ## dbl  (8): Station Latitude, Station Longitude, Route8, Route9, Route10, Rout...
    ## lgl  (2): ADA, Free Crossover
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

The data set was reformatted so that `route number` and `route name` are
distinct variables.

``` r
stn_for_A = distinct(new_metro_df, route_name == "A", ada) 

stn_for_A_ada = filter(stn_for_A, ada == TRUE)
```

There are 6 stations that serve the A train and 3 of these stations are
ADA compliant.

# Problem 2

``` r
mr_tw_df = read_excel(
  "./202309 Trash Wheel Collection Data.xlsx", sheet = "Mr. Trash Wheel", 
  skip = 1, 
  n_max = 584,
  na = c("NA", "", ".")) |>
  janitor::clean_names() |>
  mutate(
    sports_balls = as.integer(sports_balls),
    year = as.integer(year), 
    trash_wheel_type = "mr_trash_wheel") |>
  arrange(year, month)
```

    ## New names:
    ## • `` -> `...15`
    ## • `` -> `...16`

``` r
mr_tw_df = 
  select(mr_tw_df, -starts_with("x")) 

head(mr_tw_df)
```

    ## # A tibble: 6 × 15
    ##   dumpster month     year date                weight_tons volume_cubic_yards
    ##      <dbl> <chr>    <int> <dttm>                    <dbl>              <dbl>
    ## 1       25 August    2014 2014-08-04 00:00:00        4.39                 16
    ## 2       26 August    2014 2014-08-04 00:00:00        5.33                 17
    ## 3       27 August    2014 2014-08-13 00:00:00        3.58                 20
    ## 4       28 August    2014 2014-08-13 00:00:00        3.1                  17
    ## 5       29 August    2014 2014-08-19 00:00:00        1.77                 10
    ## 6       42 December  2014 2014-12-01 00:00:00        1.81                 17
    ## # ℹ 9 more variables: plastic_bottles <dbl>, polystyrene <dbl>,
    ## #   cigarette_butts <dbl>, glass_bottles <dbl>, plastic_bags <dbl>,
    ## #   wrappers <dbl>, sports_balls <int>, homes_powered <dbl>,
    ## #   trash_wheel_type <chr>

``` r
tail(mr_tw_df)
```

    ## # A tibble: 6 × 15
    ##   dumpster month  year date                weight_tons volume_cubic_yards
    ##      <dbl> <chr> <int> <dttm>                    <dbl>              <dbl>
    ## 1      583 June   2023 2023-06-28 00:00:00        2.28                 10
    ## 2      584 June   2023 2023-06-29 00:00:00        3.9                  15
    ## 3      571 March  2023 2023-03-06 00:00:00        3.14                 15
    ## 4      572 March  2023 2023-03-29 00:00:00        3.41                 15
    ## 5      579 May    2023 2023-05-04 00:00:00        3.66                 15
    ## 6      580 May    2023 2023-05-04 00:00:00        2.62                 15
    ## # ℹ 9 more variables: plastic_bottles <dbl>, polystyrene <dbl>,
    ## #   cigarette_butts <dbl>, glass_bottles <dbl>, plastic_bags <dbl>,
    ## #   wrappers <dbl>, sports_balls <int>, homes_powered <dbl>,
    ## #   trash_wheel_type <chr>

Mr. Trash Wheel excel sheet was imported as `mr_tw_df`and was cleaned.
Any unnecessary data such as non-dumpster specific data was removed
while cleaning and `trash_wheel_type` variable was added to the data
frame so that I can keep track of which trash wheel data is which when I
bind this data frame with other trash wheel data. Head and tail of the
cleaned data was checked.

``` r
prof_tw_df = 
  read_excel("./202309 Trash Wheel Collection Data.xlsx", sheet = "Professor Trash Wheel", 
  skip = 1, 
  n_max = 106, 
  na = c("NA", "", ".")) |>
  janitor::clean_names() |>
  mutate(
    sports_balls = NA, 
    trash_wheel_type = "professor_trash_wheel") |>
  arrange(year, month)

gwyn_tw_df = read_excel(
  "./202309 Trash Wheel Collection Data.xlsx", sheet = "Gwynnda Trash Wheel", 
  skip = 1, 
  n_max = 154,
  na = c("NA", "", ".")) |>
  janitor::clean_names() |>
  mutate(
    glass_bottles = NA,
    sports_balls = NA, 
    trash_wheel_type = "gwynnda_trash_wheel") |>
  arrange(year, month)

head(prof_tw_df)
```

    ## # A tibble: 6 × 15
    ##   dumpster month     year date                weight_tons volume_cubic_yards
    ##      <dbl> <chr>    <dbl> <dttm>                    <dbl>              <dbl>
    ## 1        7 April     2017 2017-04-01 00:00:00        1.82                 15
    ## 2        8 April     2017 2017-04-20 00:00:00        2.37                 15
    ## 3       15 August    2017 2017-08-04 00:00:00        2.93                 15
    ## 4       16 August    2017 2017-08-31 00:00:00        1.21                 15
    ## 5        3 February  2017 2017-02-26 00:00:00        2.32                 18
    ## 6        4 February  2017 2017-02-26 00:00:00        3.72                 15
    ## # ℹ 9 more variables: plastic_bottles <dbl>, polystyrene <dbl>,
    ## #   cigarette_butts <dbl>, glass_bottles <dbl>, plastic_bags <dbl>,
    ## #   wrappers <dbl>, homes_powered <dbl>, sports_balls <lgl>,
    ## #   trash_wheel_type <chr>

``` r
tail(prof_tw_df)
```

    ## # A tibble: 6 × 15
    ##   dumpster month      year date                weight_tons volume_cubic_yards
    ##      <dbl> <chr>     <dbl> <dttm>                    <dbl>              <dbl>
    ## 1       97 September  2022 2022-09-15 00:00:00        3.49                 15
    ## 2      103 April      2023 2023-04-10 00:00:00        2.05                 15
    ## 3      104 April      2023 2023-04-20 00:00:00        2.58                 15
    ## 4      102 February   2023 2023-02-15 00:00:00        2.41                 15
    ## 5      105 June       2023 2023-06-16 00:00:00        1.85                 15
    ## 6      106 June       2023 2023-06-29 00:00:00        2.25                 15
    ## # ℹ 9 more variables: plastic_bottles <dbl>, polystyrene <dbl>,
    ## #   cigarette_butts <dbl>, glass_bottles <dbl>, plastic_bags <dbl>,
    ## #   wrappers <dbl>, homes_powered <dbl>, sports_balls <lgl>,
    ## #   trash_wheel_type <chr>

``` r
head(gwyn_tw_df)
```

    ## # A tibble: 6 × 15
    ##   dumpster month   year date                weight_tons volume_cubic_yards
    ##      <dbl> <chr>  <dbl> <dttm>                    <dbl>              <dbl>
    ## 1        6 August  2021 2021-08-11 00:00:00        2.06                 15
    ## 2        7 August  2021 2021-08-14 00:00:00        1.9                  15
    ## 3        8 August  2021 2021-08-16 00:00:00        2.16                 15
    ## 4        9 August  2021 2021-08-16 00:00:00        2.6                  15
    ## 5       10 August  2021 2021-08-17 00:00:00        3.21                 15
    ## 6       11 August  2021 2021-08-17 00:00:00        2.44                 15
    ## # ℹ 9 more variables: plastic_bottles <dbl>, polystyrene <dbl>,
    ## #   cigarette_butts <dbl>, plastic_bags <dbl>, wrappers <dbl>,
    ## #   homes_powered <dbl>, glass_bottles <lgl>, sports_balls <lgl>,
    ## #   trash_wheel_type <chr>

``` r
tail(gwyn_tw_df)
```

    ## # A tibble: 6 × 15
    ##   dumpster month  year date                weight_tons volume_cubic_yards
    ##      <dbl> <chr> <dbl> <dttm>                    <dbl>              <dbl>
    ## 1      153 June   2023 2023-06-29 00:00:00        3.45                 15
    ## 2      139 March  2023 2023-03-03 00:00:00        2.41                 15
    ## 3      140 March  2023 2023-03-14 00:00:00        2.91                 15
    ## 4      145 May    2023 2023-05-01 00:00:00        2.85                 15
    ## 5      146 May    2023 2023-05-01 00:00:00        3.22                 15
    ## 6      147 May    2023 2023-05-04 00:00:00        3.44                 15
    ## # ℹ 9 more variables: plastic_bottles <dbl>, polystyrene <dbl>,
    ## #   cigarette_butts <dbl>, plastic_bags <dbl>, wrappers <dbl>,
    ## #   homes_powered <dbl>, glass_bottles <lgl>, sports_balls <lgl>,
    ## #   trash_wheel_type <chr>

Professor Trash Wheel and Gwynnda Trash Wheel excel sheets were also
imported and cleaned. Similar to Mr. Trash Wheel data, any variable
required for binding later was added to Professor and Gwynnda data sets.
I added three additional columns for glass bottles, sports balls and
trash wheel type to Gywnnda; I added two columns for sports balls and
trash wheel type to Professor.

Head and tail of each cleaned data set was checked.

``` r
comb_tw_df = bind_rows(prof_tw_df, gwyn_tw_df, mr_tw_df) 

trash_types = 
  select(comb_tw_df, plastic_bottles:sports_balls) |>
  names()

wgt_prof_tw_df = 
  select(prof_tw_df, weight_tons) |>
  sum()

wgt_gwyn_tw_df = select(gwyn_tw_df, weight_tons) |>
  sum()

wgt_mr_tw_df = select(mr_tw_df, weight_tons) |>
  sum()

cb_comb_tw_df = 
  comb_tw_df |>
  select(cigarette_butts) |>
  sum()
  
cb_gwyn_tw_df = 
  gwyn_tw_df |>
  filter(year == 2022, month == "June") |>
  select(cigarette_butts) |>
  sum()
```

Professor Trash Wheel, Gwynnda Trash Wheel and Mr. Trash Wheel data were
all combined into one data set named `comb_tw_df`. In the merged data
set, total 844 observations were found, where 106 observations came from
Professor Trash Wheel, 154 from Gwynnda Trash Wheel, and 584 from
Mr. Trash Wheel.

The observations are collected from May 2014 to June 2023 by Mr. Trash
Wheel; 2017 April to June 2023, Professor Trash Wheel; August 2021 to
May 2023, Gwynnda Trash Wheel.

There are 8 types of trash collected by three different Trash Wheels and
they are as follows: plastic_bottles, polystyrene, cigarette_butts,
glass_bottles, plastic_bags, wrappers, homes_powered, sports_balls.

The total weight of trash collected by Professor Trash Wheel is 216.26
tons whereas Gwynnda Trash Wheel and Mr. Trash Wheel collected 448.77
tons and 1875.1 tons, respectively.

The total number of cigarette butts collected by three Trash Wheels are
NA and Gwynnda collected 1.812^{4} cigarette butts in June of 2022.

# Problem 3

``` r
bakers_df = 
  read_csv("./gbb_datasets/bakers.csv", na = c("NA", "", ".")) |>
  janitor::clean_names() |>
  separate(
    baker_name, into = c("first_name", "last_name"), sep = " "
  ) |>
  arrange(series) |>
  relocate(series, first_name)
```

    ## Rows: 120 Columns: 5
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## chr (3): Baker Name, Baker Occupation, Hometown
    ## dbl (2): Series, Baker Age
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

``` r
bakes_df = 
  read_csv("./gbb_datasets/bakes.csv", na = c("NA", "", ".")) |>
  janitor::clean_names()|>
  rename(first_name = baker) |>
  mutate(first_name = gsub("\"", "", first_name)) 
```

    ## Rows: 548 Columns: 5
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## chr (3): Baker, Signature Bake, Show Stopper
    ## dbl (2): Series, Episode
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

``` r
results_df = 
  read_csv("./gbb_datasets/results.csv", na = c("NA", "", "."), skip = 2) |>
  janitor::clean_names() |>
  rename(first_name = baker)
```

    ## Rows: 1136 Columns: 5
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## chr (2): baker, result
    ## dbl (3): series, episode, technical
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

``` r
bakes_results_df = 
  full_join(bakes_df, results_df, by = c("series", "episode", "first_name")) |>
  pivot_wider(
    names_from = episode,
    values_from = c(signature_bake, show_stopper, technical, result)
  )

gbboff_df = 
  full_join(bakers_df, bakes_results_df, by = c("series", "first_name"))

bakers_check = anti_join(bakers_df, bakes_results_df) 
```

    ## Joining with `by = join_by(series, first_name)`

First, I imported `bakers.csv` file and cleaned it using
`janitor::clean_names`. Then, I separated the `name` variable into
`first_name` and `last_name` for later binding as other files
(e.g.`bakes.csv` and `results.csv`) only had first name under baker
information. Next, I arranged the data in the ascending series order and
relocated the data set to have series and first name as first two
columns.

Similarly, I imported and cleaned `bakes.csv` and `results.csv` files. I
renamed `baker` as `first_name` so that the variable for baker
information aligns for all three data sets. Also, for `bakes.csv`, I
eliminated unnecessary `""` marks in a value under `first_name`
variable.

I combined these two data sets into a data frame named
`bakes_results_df` and organized the data using `pivot_wider` function
to tidy up the data for further binding with `bakers_df` data set.

`bakers_df` and `bakes_results_df` were merged using `full_join`
function and the data frame was named as `gbboff_df`. `anti_join` was
used to see if the merge was performed correctly. It was confirmed that
the data sets were merged successfully and correctly as an empty tibble
was generated using `anti_join`.

``` r
write.csv(gbboff_df, "./gbb_datasets/gbboff_merged_file.csv")
```

Create a reader-friendly table showing the star baker or winner of each
episode in Seasons 5 through 10. Comment on this table – were there any
predictable overall winners? Any surprises?

``` r
viewers_df = read_csv("gbb_datasets/viewers.csv", na = c("NA", "", ".")) |>
  janitor::clean_names()
```

    ## Rows: 10 Columns: 11
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## dbl (11): Episode, Series 1, Series 2, Series 3, Series 4, Series 5, Series ...
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

``` r
head(viewers_df)
```

    ## # A tibble: 6 × 11
    ##   episode series_1 series_2 series_3 series_4 series_5 series_6 series_7
    ##     <dbl>    <dbl>    <dbl>    <dbl>    <dbl>    <dbl>    <dbl>    <dbl>
    ## 1       1     2.24     3.1      3.85     6.6      8.51     11.6     13.6
    ## 2       2     3        3.53     4.6      6.65     8.79     11.6     13.4
    ## 3       3     3        3.82     4.53     7.17     9.28     12.0     13.0
    ## 4       4     2.6      3.6      4.71     6.82    10.2      12.4     13.3
    ## 5       5     3.03     3.83     4.61     6.95     9.95     12.4     13.1
    ## 6       6     2.75     4.25     4.82     7.32    10.1      12       13.1
    ## # ℹ 3 more variables: series_8 <dbl>, series_9 <dbl>, series_10 <dbl>

``` r
avg_viewers_s1 = 
  select(viewers_df, series_1) |> 
  drop_na() |>
  pull() |>
  mean()

avg_viewers_s5 = 
  select(viewers_df, series_5) |>
  pull() |>
  mean()
```

The viewership data in `viewers.csv` was imported and cleaned. The first
10 rows of the dataset is displayed using `head` function. The average
viewership in Season 1 is 2.77 and in Season 5 is 10.0393.
